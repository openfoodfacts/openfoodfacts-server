name: Pull Request checks

on:
  pull_request:
    # we can't do that, because status are required
    # see https://stackoverflow.com/questions/66751567/return-passing-status-on-github-workflow-when-using-paths-ignore
    # paths-ignore:
    #   - "**.md"
    #   - ".github/CODEOWNERS"
    #   - ".github/PULL_REQUEST_TEMPLATE.md"
    #   - ".editorconfig"
  push:
    branches:
    - main

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
  
permissions:
  contents: read


jobs:
  filter:
    name: "Filter changed paths"
    runs-on: ubuntu-latest
    outputs:
      code_modified: ${{ steps.filter.outputs.code_modified }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get changed files
        uses: step-security/changed-files@v46
        id: changed_files

      - name: Filter non-markdown and non-docs files
        id: filter
        run: ./.github/scripts/path-filter.sh "${{ steps.changed_files.outputs.all_changed_files }}"

  lint:
    name: ðŸ•µï¸â€â™€ï¸ NPM lint
    needs: filter
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && needs.filter.outputs.code_modified == 'true'
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 1
    - uses: actions/setup-node@v4
      with:
        node-version: '22.x'
        cache: 'npm'
        cache-dependency-path: 'package-lock.json'
    - name: gulp build
      run: make front_build
    - name: lint
      run: make front_lint

  # this will build the docker image and upload as an artifact for following jobs
  build_backend:
    name: ðŸ— Build backend dev image for tests
    runs-on: ubuntu-latest
    if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4
        with:
          # needs depth to run git log below
          fetch-depth: 50
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver: docker-container
          use: true

        # Restore BuildKit cache from previous builds
      - name: Restore BuildKit cache
        uses: actions/cache@v4
        with:
          # Cache key based on files that trigger Docker rebuild (from path-filter logic)
          key: ${{ runner.os }}-docker-${{ hashFiles('Dockerfile*', 'docker-compose.yml', 'docker/**', 'cpanfile*', 'conf/apache*') }}
          restore-keys: |
            ${{ runner.os }}-docker-
          path: /tmp/.buildx-cache
          # Enable compression for faster cache restoration
          enableCrossOsArchive: false

      # Restore taxonomies cache
      - uses: actions/cache@v4
        id: cache
        with:
          path: ./build-cache
          key: taxonomies-${{ hashFiles('taxonomies/**') }}
          restore-keys: taxonomies-

      # Get current user/group IDs for proper file permissions in Docker
      - name: Get user IDs
        id: user_ids
        run: |
          echo "uid=$(id -u)" >> $GITHUB_OUTPUT
          echo "gid=$(id -g)" >> $GITHUB_OUTPUT

      - name: Build backend image with cache
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          build-args: |
            USER_UID=${{ steps.user_ids.outputs.uid }}
            USER_GID=${{ steps.user_ids.outputs.gid }}
            CPANMOPTS=--with-develop
          # Multi-layer caching strategy for maximum performance
          cache-from: |
            type=local,src=/tmp/.buildx-cache
            type=gha
          cache-to: |
            type=local,dest=/tmp/.buildx-cache-new,mode=max
            type=gha,mode=max
          load: true                   # loads the image into local docker daemon
          tags: openfoodfacts-server/backend:dev

      - name: push backend image as artifact
        uses: ishworkh/container-image-artifact-upload@v2.0.0
        with:
          image: "openfoodfacts-server/backend:dev"

      # Prepare cache for next run
      - name: Prepare cache for next run
        if: always()
        run: |
          rm -rf /tmp/.buildx-cache
          if [ -d /tmp/.buildx-cache-new ]; then
            mv /tmp/.buildx-cache-new /tmp/.buildx-cache
          fi

      - name: Setup Git and Restore Taxonomies
        run: ./.github/scripts/setup_git.sh
        
      # Update dynamic test groups before running tests
      - name: Update dynamic test groups
        run: ./.github/scripts/update_test_groups.sh

        # Set up environment variables for proper Docker user/group permissions
      - name: Set up user environment for Docker
        run: |
          echo "export USER_UID=$(id -u)" >> .envrc
          echo "export USER_GID=$(id -g)" >> .envrc

      - name: Rebuild taxonomies for Open Food Facts (off)
        run: make DOCKER_LOCAL_DATA="$(pwd)" build_taxonomies GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"

      - name: Rebuild taxonomies for Open Beauty Facts (obf)
        run: |
          source env/setenv.sh obf
          make DOCKER_LOCAL_DATA="$(pwd)" build_taxonomies GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"

      - name: Rebuild taxonomies for Open Products Facts (opf)
        run: |
          source env/setenv.sh opf
          make DOCKER_LOCAL_DATA="$(pwd)" build_taxonomies GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"

      - name: Rebuild taxonomies for Open Pet Food Facts (opff)
        run: |
          source env/setenv.sh opff
          make DOCKER_LOCAL_DATA="$(pwd)" build_taxonomies GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"

  check_perl:
    name: ðŸª Check Perl
    needs: [filter, build_backend]
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && needs.filter.outputs.code_modified == 'true'
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 1
    - name: Setup Git and Restore Taxonomies
      run: ./.github/scripts/setup_git.sh
    - uses: actions/cache/restore@v4
      id: cache
      with:
        path: ./build-cache
        key: taxonomies-${{ hashFiles('taxonomies/**') }}
        restore-keys: taxonomies-
    - name: Download backend image from artifacts
      id: downloadbackendimage
      uses: ishworkh/container-image-artifact-download@v2.1.0
      with:
        image: "openfoodfacts-server/backend:dev"
        download_tmp_dir: ${{ runner.temp }}
    - name: build taxonomies (should use cache)
      run: make DOCKER_LOCAL_DATA="$(pwd)" build_taxonomies GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"
    - name: check taxonomies
      run: make check_taxonomies
    - name: check perltidy
      run: make check_perltidy
    - name: check perlcritic
      run: make check_critic
    - name: check perl
      run: make check_perl

  unit_tests:
    name: ðŸª Perl Unit Tests
    needs: [filter, build_backend]
    runs-on: ubuntu-latest
    if: ((github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'pull_request') && needs.filter.outputs.code_modified == 'true'
    strategy:
      fail-fast: false
      matrix:
        test-group: [1, 2, 3, 4, 5, 6]
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 1
    
    # Restore cached taxonomies built in build_backend job
    # This avoids rebuilding taxonomies for each test group
    - uses: actions/cache/restore@v4
      id: taxonomies_cache
      with:
        path: ./build-cache
        key: taxonomies-${{ hashFiles('taxonomies/**') }}
        restore-keys: taxonomies-
    
    # Cache dynamic test groups and timing data
    # This enables persistent learning and avoids regenerating groups unnecessarily
    - uses: actions/cache@v4
      id: test_groups_cache
      with:
        path: ./.test_groups_cache
        key: test-groups-unit-${{ hashFiles('tests/unit/**/*.t') }}-${{ hashFiles('scripts/dynamic_test_grouper.pl') }}
        restore-keys: |
          test-groups-unit-${{ hashFiles('tests/unit/**/*.t') }}-
          test-groups-unit-
    
    - name: Setup Git and Restore Taxonomies
      run: ./.github/scripts/setup_git.sh
    
    # Update dynamic test groups before running tests
    # This ensures optimal load balancing based on historical timing data
    - name: Update dynamic test groups
      run: |
        echo "ðŸ¥« Checking and updating dynamic test groups..."
        ./.github/scripts/update_test_groups.sh --stats
        
        # Generate test groups for Makefile if needed
        if [ ! -f ".test_groups_cache/unit_groups.mk" ]; then
          echo "ðŸ¥« Generating unit test groups for Makefile..."
          perl scripts/dynamic_test_grouper.pl --type=unit --groups=6 > .test_groups_cache/unit_groups.mk
        fi
    
    # Download the Docker image built in build_backend job as an artifact
    # This reuses the cached Docker image instead of rebuilding it
    - name: Download backend image from artifacts
      id: downloadbackendimage
      uses: ishworkh/container-image-artifact-download@v2.0.0
      with:
        image: "openfoodfacts-server/backend:dev"       
    
    # Clean up downloaded file to save GitHub Actions storage space
    # The image is already loaded into Docker daemon, file no longer needed
    - name: Remove downloaded image
      env:
        FILE: "${{ steps.downloadbackendimage.outputs.download_path }}"
      run: rm $FILE
    
    # Build test-specific taxonomies and language files
    # These use the cached taxonomies from build_backend when possible
    - name: Build taxonomies for tests
      run: make DOCKER_LOCAL_DATA="$(pwd)" build_taxonomies_test GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"
    - name: Build language files for tests
      run: make DOCKER_LOCAL_DATA="$(pwd)" build_lang_test GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"
    
    # Run unit tests for this specific test group (parallel execution)
    # Matrix strategy splits tests across 6 parallel jobs for faster execution
    # Now uses dynamically generated groups for optimal load balancing
    - name: Run unit test group ${{ matrix.test-group }}
      run: |
        echo "ðŸ¥« Running dynamically balanced unit test group ${{ matrix.test-group }}..."
        make codecov_prepare
        make COVER_OPTS='-e HARNESS_PERL_SWITCHES="-MDevel::Cover=+ignore,tests/"' DOCKER_LOCAL_DATA="$(pwd)" unit_test_group TEST_GROUP=${{ matrix.test-group }} GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"
    
    # Update timing data after test execution for future optimization
    # This enables the system to learn and improve load balancing over time
    - name: Update test timing data
      if: always()
      run: |
        echo "ðŸ¥« Updating timing data from test results..."
        if [ -d "tests/unit/outputs" ] && [ "$(ls -A tests/unit/outputs/*.xml 2>/dev/null)" ]; then
          perl scripts/dynamic_test_grouper.pl --type=unit --update-timings --junit-dir=tests/unit/outputs
          echo "ðŸ¥« Timing data updated successfully"
        else
          echo "ðŸ¥« No JUnit XML files found, skipping timing update"
        fi
    
    - name: generate coverage results
      # even if tests failed
      if: always()
      run: |
        make coverage_txt
        make codecov
    - uses: codecov/codecov-action@v5
      if: always()
      with:
        files: cover_db/codecov.json
        token: ${{ secrets.CODECOV_TOKEN }}
    - name: Upload test results to Codecov
      if: ${{ !cancelled() }}
      uses: codecov/test-results-action@v1
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./tests/unit/outputs/junit_group_${{ matrix.test-group }}.xml

  integration_tests:
    name: ðŸª Perl Integration Tests
    needs: [filter, build_backend]
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && needs.filter.outputs.code_modified == 'true'
    strategy:
      fail-fast: false
      matrix:
        test-group: [1, 2, 3, 4, 5, 6, 7, 8, 9]
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 1
    
    - uses: actions/cache/restore@v4
      id: taxonomies_cache
      with:
        path: ./build-cache
        key: taxonomies-${{ hashFiles('taxonomies/**') }}
        restore-keys: taxonomies-
    
    # Cache dynamic test groups and timing data for integration tests
    # Integration tests typically have more variable execution times
    - uses: actions/cache@v4
      id: test_groups_cache
      with:
        path: ./.test_groups_cache
        key: test-groups-integration-${{ hashFiles('tests/integration/**/*.t') }}-${{ hashFiles('scripts/dynamic_test_grouper.pl') }}
        restore-keys: |
          test-groups-integration-${{ hashFiles('tests/integration/**/*.t') }}-
          test-groups-integration-
    
    - name: Setup Git and Restore Taxonomies
      run: ./.github/scripts/setup_git.sh
  
    # Update dynamic test groups before running tests
    # Integration tests benefit more from timing-based grouping due to variable execution times
    - name: Update dynamic test groups
      run: |
        echo "ðŸ¥« Checking and updating dynamic integration test groups..."
        ./.github/scripts/update_test_groups.sh --stats
        
        # Generate test groups for Makefile if needed
        if [ ! -f ".test_groups_cache/integration_groups.mk" ]; then
          echo "ðŸ¥« Generating integration test groups for Makefile..."
          perl scripts/dynamic_test_grouper.pl --type=integration --groups=9 > .test_groups_cache/integration_groups.mk
        fi

    - name: Download backend image from artifacts
      id: downloadbackendimage
      uses: ishworkh/container-image-artifact-download@v2.0.0
      with:
        image: "openfoodfacts-server/backend:dev"       
    
    - name: Remove downloaded image
      env:
        FILE: "${{ steps.downloadbackendimage.outputs.download_path }}"
      run: rm $FILE
    
    - name: Build taxonomies for tests
      run: make DOCKER_LOCAL_DATA="$(pwd)" build_taxonomies_test GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"
    - name: Build language files for tests
      run: make DOCKER_LOCAL_DATA="$(pwd)" build_lang_test GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"
    
    # Run integration tests for this specific test group (parallel execution)
    # Matrix strategy splits tests across 9 parallel jobs (more than unit tests)
    # Integration tests typically take longer and test end-to-end functionality
    # Now uses dynamically generated groups for optimal load balancing
    - name: Run integration test group ${{ matrix.test-group }}
      run: |
        echo "ðŸ¥« Running dynamically balanced integration test group ${{ matrix.test-group }}..."
        make codecov_prepare
        make COVER_OPTS='-e HARNESS_PERL_SWITCHES="-MDevel::Cover=+ignore,tests/"' DOCKER_LOCAL_DATA="$(pwd)" integration_test_group TEST_GROUP=${{ matrix.test-group }} GITHUB_TOKEN="${{ secrets.TAXONOMY_CACHE_GITHUB_TOKEN }}"
    
    # Update timing data after test execution for future optimization
    # Integration test timing data is especially valuable due to higher variance
    - name: Update test timing data
      if: always()
      run: |
        echo "ðŸ¥« Updating integration test timing data from test results..."
        if [ -d "tests/integration/outputs" ] && [ "$(ls -A tests/integration/outputs/*.xml 2>/dev/null)" ]; then
          perl scripts/dynamic_test_grouper.pl --type=integration --update-timings --junit-dir=tests/integration/outputs
          echo "ðŸ¥« Integration test timing data updated successfully"
        else
          echo "ðŸ¥« No JUnit XML files found, skipping timing update"
        fi
    
    - name: generate coverage results
      # even if tests failed
      if: always()
      run: |
        make coverage_txt
        make codecov
    - uses: codecov/codecov-action@v5
      if: always()
      with:
        files: cover_db/codecov.json
        token: ${{ secrets.CODECOV_TOKEN }}
    - name: Upload test results to Codecov
      if: ${{ !cancelled() }}
      uses: codecov/test-results-action@v1
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./tests/integration/outputs/junit_group_${{ matrix.test-group }}.xml
    
  tests_dev:
    name: ðŸ§ª Test make dev
    needs: [filter, build_backend]  # build_backend - only to avoid building taxonomies
    if: github.event_name == 'pull_request' && needs.filter.outputs.code_modified == 'true'
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 1
    - uses: actions/cache/restore@v4
      id: cache
      with:
        path: ./build-cache
        key: taxonomies-${{ hashFiles('taxonomies/**') }}
        restore-keys: taxonomies-
    - name: Download backend image from artifacts
      id: downloadbackendimage
      uses: ishworkh/container-image-artifact-download@v2.1.0
      with:
        image: "openfoodfacts-server/backend:dev"
        download_tmp_dir: ${{ runner.temp }}
    - name: set right UID and GID in .envrc
      run: |
        rm -f .envrc
        echo "export USER_UID=$(id -u)" >> .envrc
        echo "export USER_GID=$(id -g)" >> .envrc
    - name: Test make dev
      run: |
        make DOCKER_LOCAL_DATA="$(pwd)" SKIP_SAMPLE_IMAGES=1 dev_no_build
        make status
    - name: Test all is running
      run: make livecheck || ( tail -n 300 logs/apache2/*error*log; docker compose logs; false )
    - name: test clean
      run: make hdown

  test_deployment:
    name: ðŸ¦¾ Some test of deployment tools
    needs: filter
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && needs.filter.outputs.code_modified == 'true'
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 1
    - name: verify apache2 envvars is correct
      run: |
        env/setenv.sh off;
        sh -c ". conf/apache-2.4/off-envvars"
        sh -c "APACHE_CONFDIR=/etc/apache2-priority; . conf/apache-2.4/off-envvars"
