import json
import re
import sys

# Load the query.json file generated by https://query.wikidata.org/
try:
    with open('../food/wikidata-query-output-example.json', 'r') as f:
        query_data = json.load(f)
except FileNotFoundError:
    print("Error: Could not find '../food/wikidata-query-output-example.json'.")
    print("Please ensure the Wikidata query output file exists at the specified path.")
    sys.exit(1)
except json.JSONDecodeError as e:
    print(f"Error: Failed to parse JSON from '../food/wikidata-query-output-example.json': {e}")
    sys.exit(1)
except IOError as e:
    print(f"Error: Could not read '../food/wikidata-query-output-example.json': {e}")
    sys.exit(1)

# Create a dictionary to map item labels to QIDs
# Track duplicates to warn the user
label_to_qid = {}
duplicate_labels = {}
filtered_qid_labels = []
for item in query_data:
    label = item.get('itemLabel')
    qid = item.get('item', '').split('/')[-1]
    if label and qid:
        # Filter out entries where itemLabel is just a QID (e.g., "Q1960572")
        # These indicate missing labels in Wikidata and won't match taxonomy entries
        if re.match(r'^Q\d+$', label):
            filtered_qid_labels.append((label, qid))
            continue
        
        label_lower = label.lower()
        if label_lower in label_to_qid:
            # Track duplicate labels with all their QIDs
            if label_lower not in duplicate_labels:
                duplicate_labels[label_lower] = [label_to_qid[label_lower]]
            duplicate_labels[label_lower].append(qid)
        label_to_qid[label_lower] = qid

# Warn about filtered QID-only labels
if filtered_qid_labels:
    print(f"Info: Filtered out {len(filtered_qid_labels)} entries with QID-only labels (no human-readable text).")
    print("These entries don't have labels in the query language and won't match taxonomy entries.")
    print()

# Warn about duplicate labels
if duplicate_labels:
    print(f"Warning: {len(duplicate_labels)} duplicate label(s) found (case-insensitive).")
    print("Only the last QID for each duplicate label will be used:")
    for label, qids in duplicate_labels.items():
        print(f"  '{label}': {', '.join(qids)} (using {qids[-1]})")
    print()

# Read the ingredients.txt file
try:
    with open('/taxonomies/food/ingredients.txt', 'r') as f:
        categories_content = f.read()
except FileNotFoundError:
    print("Error: Could not find '/taxonomies/food/ingredients.txt'.")
    print("Please ensure the taxonomy file exists at the specified path.")
    sys.exit(1)
except IOError as e:
    print(f"Error: Could not read '/taxonomies/food/ingredients.txt': {e}")
    sys.exit(1)

# Process the ingredients.txt file
updated_content = categories_content
updated_count = 0

# Collect all replacements first to avoid position shift issues
replacements = []  # List of tuples: (block_start, block_end, new_block, label, qid)

for label, qid in label_to_qid.items():
    # We need to be careful with special characters in the label
    escaped_label = re.escape(label)
    
    # The label can be a value of any key.
    # The pattern looks for a line starting with a language code, a colon, and then the label.
    pattern = r"^[a-z]{2,3}:\s*" + escaped_label + r"\s*$"
    
    for match in re.finditer(pattern, updated_content, re.IGNORECASE | re.MULTILINE):
        start_index = match.start()
        
        # Find the start of the block
        block_start = updated_content.rfind('< en:', 0, start_index)
        if block_start == -1:
            continue
            
        # Find the end of the block
        block_end = updated_content.find('\n\n', start_index)
        if block_end == -1:
            block_end = len(updated_content)
            
        block = updated_content[block_start:block_end]
        
        # Check if the block already has an active (non-commented) wikidata:en: line
        has_active_wikidata = re.search(r'^\s*wikidata:en:', block, re.MULTILINE)
        
        if not has_active_wikidata:
            # Check if the block has a commented #wikidata:en: line
            if '#wikidata:en:' in block:
                # Replace it with the new wikidata line
                new_block = block.replace('#wikidata:en:', f'wikidata:en: {qid}')
                replacements.append((block_start, block_end, new_block, label, qid))
                # We assume one match is enough per label
                break
            else:
                # No wikidata line at all, we need to add one
                # Find the best place to insert it - after the last language line
                lines = block.split('\n')
                # None indicates no language line found yet
                insert_index = None
                
                # Prefixes that are not language codes
                non_language_prefixes = {
                    'wikidata', 'wikipedia', 'description', 'comment', 'allergens',
                    'carbon_footprint_fr_foodges_ingredient', 'carbon_footprint_fr_foodges_value',
                    'ciqual_food_code', 'ciqual_food_name', 'ciqual_proxy_food_code', 'ciqual_proxy_food_name',
                    'agribalyse_food_code', 'agribalyse_proxy_food_code', 'agribalyse_proxy_food_name',
                    'ecobalyse', 'ecobalyse_proxy', 'from_palm_oil', 'likely_allergens',
                    'nova', 'nutriscore_fruits_vegetables_nuts', 'nutriscore_red_meat',
                    'openfoodfacts', 'oqali_family', 'origin', 'processing', 'synonyms'
                }
                
                # Find the last line that starts with a language code (e.g., "en:", "fr:", etc.)
                for i, line in enumerate(lines):
                    line_stripped = line.strip()
                    if line_stripped:
                        # Extract the prefix before the first colon
                        prefix_match = re.match(r'^([a-z]+):', line_stripped)
                        if prefix_match:
                            prefix = prefix_match.group(1)
                            # Check if it's a valid language code (2-3 letters per ISO 639-1/2/3)
                            # Excludes prefixes with underscores and known non-language prefixes
                            if 2 <= len(prefix) <= 3 and prefix not in non_language_prefixes:
                                insert_index = i
                
                # If we found a language line, insert after it
                if insert_index is not None:
                    # Insert the wikidata line after the last language line
                    lines.insert(insert_index + 1, f'wikidata:en: {qid}')
                    new_block = '\n'.join(lines)
                    replacements.append((block_start, block_end, new_block, label, qid))
                    # We assume one match is enough per label
                    break
                else:
                    # No language lines found in block - this is unusual, log it
                    print(f"Warning: No language lines found in block for label '{label}', skipping wikidata addition")


# Apply replacements in reverse order (from end to start) to avoid position shift issues
replacements.sort(key=lambda x: x[0], reverse=True)
for block_start, block_end, new_block, label, qid in replacements:
    updated_content = updated_content[:block_start] + new_block + updated_content[block_end:]
    updated_count += 1
    print(f"Updated entry for '{label}' with QID '{qid}'")

# Write the updated content back to the file
try:
    with open('../food/ingredients.txt', 'w') as f:
        f.write(updated_content)
except IOError as e:
    print(f"Error: Could not write to '../food/ingredients.txt': {e}")
    sys.exit(1)

print(f"\nFile updated successfully. {updated_count} entries were updated.")
